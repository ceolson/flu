{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/conda/envs/deepchem/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import deepchem as dc\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import debug as tf_debug\n",
    "from deepchem.utils.genomics import encode_fasta_sequence\n",
    "from Bio import SeqIO\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "config.gpu_options.allow_growth = True\n",
    "config.log_device_placement = False\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "tf.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_train_flat = x_train.reshape([len(x_train),-1])\n",
    "\n",
    "max_size = 28*28\n",
    "encode_length = 1\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 784)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(x_train_flat[:batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(filter_name1,bias_name1,filter_name2,bias_name2,model,in_dim,out_dim,in_tensor):\n",
    "    with tf.variable_scope('',reuse=tf.AUTO_REUSE):\n",
    "        filter1 = tf.get_variable(filter_name1,collections=[model],trainable=True,shape=[5,in_dim,64])\n",
    "        bias1 = tf.get_variable(bias_name1,collections=[model],trainable=True,shape=[max_size,64])\n",
    "        filter2 = tf.get_variable(filter_name2,collections=[model],trainable=True,shape=[5,64,out_dim])\n",
    "        bias2 = tf.get_variable(bias_name2,collections=[model],trainable=True,shape=[max_size,out_dim])\n",
    "\n",
    "        x = in_tensor\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "        \n",
    "        x = tf.nn.conv1d(x,filters=filter1,padding='SAME',stride=1)\n",
    "        x = tf.add(x,bias1)\n",
    "            \n",
    "        x = tf.nn.leaky_relu(x)\n",
    "        x = tf.nn.conv1d(x,filters=filter2,padding='SAME',stride=1)\n",
    "        x = tf.add(x,bias2)\n",
    "\n",
    "    return x+0.3*in_tensor\n",
    "    \n",
    "def dense(matrix,bias,model,in_dim,out_dim,in_tensor):\n",
    "    with tf.variable_scope('',reuse=tf.AUTO_REUSE):\n",
    "        W = tf.get_variable(matrix,collections=[model],trainable=True,shape=[in_dim,out_dim])\n",
    "        b = tf.get_variable(bias,collections=[model],trainable=True,shape=[out_dim,])\n",
    "\n",
    "    return tf.matmul(in_tensor,W) + b\n",
    "\n",
    "\n",
    "def conv(filter_name,bias_name,model,filter_shape,in_tensor):\n",
    "    with tf.variable_scope('',reuse=tf.AUTO_REUSE):\n",
    "        filt = tf.get_variable(filter_name,collections=[model],trainable=True,shape=filter_shape)\n",
    "        bias = tf.get_variable(bias_name,collections=[model],trainable=True,shape=[max_size,filter_shape[-1]])\n",
    "        \n",
    "    out = tf.nn.conv1d(in_tensor,filters=filt,padding='SAME',stride=1)\n",
    "    out = tf.add(out,bias)\n",
    "    return out\n",
    "    \n",
    "# Generator\n",
    "\n",
    "def generator(seed):\n",
    "    seed = tf.reshape(seed,(batch_size,100),name='generator.reshape1')\n",
    "    \n",
    "    seed2 = dense('generator.dense1.matrix','generator.dense1.bias','generator',100,max_size*64,seed)\n",
    "    seed2 = tf.nn.leaky_relu(seed2)\n",
    "    seed2 = tf.reshape(seed2,[batch_size,max_size,64])\n",
    "    \n",
    "    x = residual_block('generator.res1.filter1','generator.res1.bias1','generator.res1.filter2','generator.res1.bias2','generator',64,64,seed2)\n",
    "    x = residual_block('generator.res2.filter1','generator.res2.bias1','generator.res2.filter2','generator.res2.bias2','generator',64,64,x)\n",
    "    x = residual_block('generator.res3.filter1','generator.res3.bias1','generator.res3.filter2','generator.res3.bias2','generator',64,64,x)\n",
    "    x = residual_block('generator.res4.filter1','generator.res4.bias1','generator.res4.filter2','generator.res4.bias2','generator',64,64,x)\n",
    "    x = residual_block('generator.res5.filter1','generator.res5.bias1','generator.res5.filter2','generator.res5.bias2','generator',64,64,x)\n",
    "\n",
    "    x = conv('generator.conv1.filter','generator.conv1.bias','generator',(5,64,encode_length),x)\n",
    "    \n",
    "    synthetic = tf.reshape(x,[batch_size,max_size])\n",
    "    return synthetic\n",
    "\n",
    "# Discriminator\n",
    "\n",
    "def discriminator(sequence):\n",
    "    sequence = tf.reshape(sequence,[batch_size,max_size,encode_length])\n",
    "    x = conv('discriminator.conv1.filter','discriminator.conv1.bias','discriminator',(5,encode_length,64),sequence)\n",
    "    x = tf.nn.leaky_relu(x)\n",
    "    \n",
    "    x = residual_block('discriminator.res1.filter1','discriminator.res1.bias1','discriminator.res1.filter2','discriminator.res1.bias1','discriminator',64,64,x)\n",
    "    x = residual_block('discriminator.res2.filter1','discriminator.res2.bias1','discriminator.res2.filter2','discriminator.res2.bias1','discriminator',64,64,x)\n",
    "    x = residual_block('discriminator.res3.filter1','discriminator.res3.bias1','discriminator.res3.filter2','discriminator.res3.bias1','discriminator',64,64,x)\n",
    "    x = residual_block('discriminator.res4.filter1','discriminator.res4.bias1','discriminator.res4.filter2','discriminator.res4.bias1','discriminator',64,64,x)\n",
    "    x = residual_block('discriminator.res5.filter1','discriminator.res5.bias1','discriminator.res5.filter2','discriminator.res5.bias1','discriminator',64,64,x)\n",
    "    \n",
    "    x = tf.reshape(x,(batch_size,max_size*64))\n",
    "    \n",
    "    output = dense('discriminator.dense1.matrix','discriminator.dense1.bias','discriminator',max_size*64,1,x)\n",
    "    return output\n",
    "    \n",
    "### Constructing the loss function\n",
    "\n",
    "real_images = tf.placeholder(float,name='real_images')\n",
    "noise = tf.placeholder(float,name='noise')\n",
    "\n",
    "fake_images = generator(noise)\n",
    "fake_images = tf.identity(fake_images,name='fake_images')\n",
    "\n",
    "# Sampling images in the encoded space between the fake ones and the real ones\n",
    "\n",
    "interpolation_coeffs = tf.random_uniform(shape=(batch_size,1,1))\n",
    "sampled_images = tf.add(real_images,tf.multiply(tf.subtract(fake_images,real_images),interpolation_coeffs),name='sampled_images')\n",
    "\n",
    "# Gradient penalty\n",
    "gradients = tf.gradients(discriminator(sampled_images),sampled_images,name='gradients')[0]\n",
    "norms = tf.norm(gradients,axis=[1,2])\n",
    "score = tf.reduce_mean(tf.square(tf.subtract(norms,1.)),name='gradient_penalty')\n",
    "\n",
    "# Loss based on discriminator's predictions\n",
    "\n",
    "pred_real = tf.reshape(discriminator(real_images),[-1])\n",
    "pred_real = tf.identity(pred_real,name='pred_real')\n",
    "\n",
    "pred_fake = tf.reshape(discriminator(fake_images),[-1])\n",
    "pred_fake = tf.identity(pred_fake,name='pred_fake')\n",
    "\n",
    "diff = tf.reduce_mean(tf.subtract(pred_fake,pred_real))\n",
    "\n",
    "# Discriminator wants fake sequences to be labeled 0, real to be labeled 1\n",
    "disc_loss = tf.add(diff,tf.multiply(tf.constant(10.),score),name='disc_loss')\n",
    "\n",
    "# Generator wants fake sequences to be labeled 1\n",
    "gen_loss = - tf.reduce_mean(pred_fake,name='gen_loss')\n",
    "\n",
    "# For tracking using tensorboard\n",
    "\n",
    "a = tf.summary.scalar('discriminator_difference', diff)\n",
    "b = tf.summary.scalar('generator_difference',gen_loss)\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "# Optimizers\n",
    "disc_optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.0001)\n",
    "gen_optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.0001)\n",
    "\n",
    "train_discriminator = disc_optimizer.minimize(disc_loss,var_list=tf.get_collection('discriminator'),name='train_discriminator')\n",
    "grads_discriminator = disc_optimizer.compute_gradients(disc_loss,var_list=tf.get_collection('discriminator'))\n",
    "\n",
    "train_generator = gen_optimizer.minimize(gen_loss,var_list=tf.get_collection('generator'),name='train_generator')\n",
    "grads_generator = gen_optimizer.compute_gradients(gen_loss,var_list=tf.get_collection('generator'))\n",
    "\n",
    "init = tf.initializers.variables(tf.get_collection('discriminator')+tf.get_collection('generator'))\n",
    "\n",
    "writer = tf.summary.FileWriter('/home/ceolson0/Documents/tensorboard',sess.graph)\n",
    "saver = tf.train.Saver(tf.get_collection('discriminator')+tf.get_collection('generator'))\n",
    "### Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############\n",
      "6331793\n"
     ]
    }
   ],
   "source": [
    "sess.run(init)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print('############')\n",
    "print(np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()]))\n",
    "epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gan17, epoch  0\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Input to reshape is a tensor with 7840000 values, but the requested shape has 78400\n\t [[node Reshape_14 (defined at <ipython-input-7-84e1f0d6a05a>:60) ]]\n\t [[node Mean_1 (defined at <ipython-input-7-84e1f0d6a05a>:101) ]]\n\nCaused by op 'Reshape_14', defined at:\n  File \"/software/conda/envs/deepchem/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/software/conda/envs/deepchem/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/software/conda/envs/deepchem/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/software/conda/envs/deepchem/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/software/conda/envs/deepchem/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-84e1f0d6a05a>\", line 89, in <module>\n    gradients = tf.gradients(discriminator(sampled_images),sampled_images,name='gradients')[0]\n  File \"<ipython-input-7-84e1f0d6a05a>\", line 60, in discriminator\n    sequence = tf.reshape(sequence,[batch_size,max_size,encode_length])\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 7179, in reshape\n    \"Reshape\", tensor=tensor, shape=shape, name=name)\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Input to reshape is a tensor with 7840000 values, but the requested shape has 78400\n\t [[node Reshape_14 (defined at <ipython-input-7-84e1f0d6a05a>:60) ]]\n\t [[node Mean_1 (defined at <ipython-input-7-84e1f0d6a05a>:101) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/software/conda/envs/deepchem/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/software/conda/envs/deepchem/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/software/conda/envs/deepchem/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 7840000 values, but the requested shape has 78400\n\t [[{{node Reshape_14}}]]\n\t [[{{node Mean_1}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-7e69f718ebc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mreal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mnoise_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_discriminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrads_discriminator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mreal_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnoise_input\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training discriminator\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/software/conda/envs/deepchem/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/software/conda/envs/deepchem/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/software/conda/envs/deepchem/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/software/conda/envs/deepchem/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 7840000 values, but the requested shape has 78400\n\t [[node Reshape_14 (defined at <ipython-input-7-84e1f0d6a05a>:60) ]]\n\t [[node Mean_1 (defined at <ipython-input-7-84e1f0d6a05a>:101) ]]\n\nCaused by op 'Reshape_14', defined at:\n  File \"/software/conda/envs/deepchem/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/software/conda/envs/deepchem/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/software/conda/envs/deepchem/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/software/conda/envs/deepchem/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/software/conda/envs/deepchem/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-84e1f0d6a05a>\", line 89, in <module>\n    gradients = tf.gradients(discriminator(sampled_images),sampled_images,name='gradients')[0]\n  File \"<ipython-input-7-84e1f0d6a05a>\", line 60, in discriminator\n    sequence = tf.reshape(sequence,[batch_size,max_size,encode_length])\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 7179, in reshape\n    \"Reshape\", tensor=tensor, shape=shape, name=name)\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/software/conda/envs/deepchem/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Input to reshape is a tensor with 7840000 values, but the requested shape has 78400\n\t [[node Reshape_14 (defined at <ipython-input-7-84e1f0d6a05a>:60) ]]\n\t [[node Mean_1 (defined at <ipython-input-7-84e1f0d6a05a>:101) ]]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print('\\ngan17, epoch ',epoch)\n",
    "\n",
    "    \n",
    "    # Train discriminator\n",
    "    for i in range(5):\n",
    "        real = np.random.permutation(x_train_flat)[:batch_size].astype(np.float32)\n",
    "        noise_input = np.random.normal(0,1,(batch_size,100))\n",
    "        _,d_loss,grads = sess.run([train_discriminator,diff,grads_discriminator],feed_dict={real_images:real,noise:noise_input})\n",
    "        print(\"Training discriminator\",d_loss)\n",
    "            \n",
    "    # Train generator\n",
    "\n",
    "    real = np.random.permutation(x_train_flat)[:batch_size].astype(np.float32)\n",
    "    noise_input = np.random.normal(0,1,(batch_size,100))\n",
    "    _,g_loss,grads = sess.run([train_generator,gen_loss,grads_generator],feed_dict={noise:noise_input})\n",
    "    print(\"Training generator\",g_loss)\n",
    "\n",
    "    print(\"Generator loss: \",g_loss)\n",
    "    print(\"Discriminator loss: \",d_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(noise_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepChem (Python 3.7)",
   "language": "python",
   "name": "deepchem"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
